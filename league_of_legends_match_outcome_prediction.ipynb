{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0131c903",
   "metadata": {},
   "source": [
    "### League of Legends Match Predictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbf5a5",
   "metadata": {},
   "source": [
    "Goal: Predict the outcome of a LoL match (win/loss for a team) based on historical game statistics and player/team features using machine learning techniques.\n",
    "\n",
    "Objectives:\n",
    "\n",
    "1. Collect and preprocess match data from Riot Games API or Kaggle datasets\n",
    "\n",
    "2. Perform exploratory data analysis (EDA) and feature engineering\n",
    "\n",
    "3. Build predictive models using machine learning algorithms (e.g., Random Forest, XGBoost)\n",
    "\n",
    "4. Evaluate models using accuracy, precision, recall, and F1-score\n",
    "\n",
    "5. Deploy a simple interface to predict match outcomes from new game data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d40a10",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821f76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv(\"league_of_legends_data_large.csv\")\n",
    "\n",
    "# Features and target\n",
    "X = dataset.drop(\"win\", axis=1)\n",
    "y = dataset[\"win\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test  = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94055f16",
   "metadata": {},
   "source": [
    "### Logistic Regression Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae21c1df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_inputs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ceb183",
   "metadata": {},
   "source": [
    "### Model Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce2c10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_outputs = model(X_train)\n",
    "    train_loss = criterion(train_outputs, y_train)\n",
    "\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    train_losses.append(train_loss.item())\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        test_loss = criterion(test_outputs, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "            f\"Train Loss: {train_loss.item():.4f} \"\n",
    "            f\"Test Loss: {test_loss.item():.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c508a5",
   "metadata": {},
   "source": [
    "### Model Optimization and Evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30782925",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_pred = (model(X_train) >= 0.5).float()\n",
    "    test_pred  = (model(X_test) >= 0.5).float()\n",
    "\n",
    "    train_acc = (train_pred == y_train).float().mean().item()\n",
    "    test_acc  = (test_pred == y_test).float().mean().item()\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Testing Accuracy:  {test_acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test.numpy(),\n",
    "        test_pred.numpy(),\n",
    "        target_names=[\"Loss\", \"Win\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03c635",
   "metadata": {},
   "source": [
    "### Optimized Training (Momentum + Weight Decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b27cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c10a",
   "metadata": {},
   "source": [
    "### Saving Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db8f22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"league_match_predictor.pth\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = LogisticRegressionModel(input_dim)\n",
    "loaded_model.load_state_dict(torch.load(\"league_match_predictor.pth\"))\n",
    "loaded_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    reload_pred = (loaded_model(X_test) >= 0.5).float()\n",
    "    reload_acc = (reload_pred == y_test).float().mean().item()\n",
    "\n",
    "print(f\"Reloaded Model Accuracy: {reload_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57f9b7",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d217edc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.05, 0.1]\n",
    "accuracies = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = LogisticRegressionModel(input_dim)\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=lr, momentum=0.9, weight_decay=0.01\n",
    "    )\n",
    "\n",
    "    for _ in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = (model(X_test) >= 0.5).float()\n",
    "        acc = (preds == y_test).float().mean().item()\n",
    "        accuracies[lr] = acc\n",
    "\n",
    "    print(f\"LR {lr}: Test Accuracy = {acc*100:.2f}%\")\n",
    "\n",
    "best_lr = max(accuracies, key=accuracies.get)\n",
    "print(f\"Best Learning Rate: {best_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5350c90",
   "metadata": {},
   "source": [
    "### Feature Importance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4988162",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_model = LogisticRegressionModel(input_dim)\n",
    "optimizer = optim.SGD(\n",
    "    best_model.parameters(), lr=best_lr, momentum=0.9, weight_decay=0.01\n",
    ")\n",
    "\n",
    "for _ in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = best_model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Extract feature importance\n",
    "# Positive weights increase win probability\n",
    "# Negative weights decrease win probability\n",
    "\n",
    "weights = best_model.linear.weight.detach().numpy().flatten()\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": weights\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b46bff7",
   "metadata": {},
   "source": [
    "### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a1e13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "top_features = feature_importance.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features[\"Feature\"], top_features[\"Importance\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
